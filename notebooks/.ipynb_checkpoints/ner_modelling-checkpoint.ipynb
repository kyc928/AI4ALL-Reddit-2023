{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15372cf9-c409-4917-a8a5-f79eb8ca3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84aab659-371f-42ea-9874-4c51352c504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/reddit_scraping/ner_labels.json') as json_file:\n",
    "    ner_labels = pd.DataFrame(json.load(json_file))\n",
    "\n",
    "label2id = {\n",
    "    'O': 0,\n",
    "    'B-age': 1, \n",
    "    'I-age': 2,\n",
    "    'B-age_unit': 3,\n",
    "    'I-age_unit': 4\n",
    "}\n",
    "\n",
    "id2label = {\n",
    "    0: 'O',\n",
    "    1: 'B-age',\n",
    "    2: 'I-age',\n",
    "    3: 'B-age_unit',\n",
    "    4: 'I-age_unit',\n",
    "}\n",
    "\n",
    "ner_labels['ner_tags'] = ner_labels['token_labels'].map(lambda x: [label2id[y] for y in x])\n",
    "\n",
    "ner_labels = Dataset.from_pandas(ner_labels[['post_id', 'context', 'tokens', 'ner_tags']].rename({'tokens': 'words'}, axis = 1))\n",
    "ner_labels = ner_labels.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14fbf4cb-3999-45c8-9d91-e69b08644317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5558c8ca614cdea7e659fef3d67b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce658cae981f43a18b231bc5f3452144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/252 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"words\"], truncation=True, padding=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_ner_labels = ner_labels.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486658d3-8775-4242-9063-ef7b7848eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b765cb-47eb-42d8-819c-ff3bb9aaf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475d5984-268b-4b1b-bc10-d51b41d1a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7627490c-a3bb-4749-910a-6fe714cd91a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert-base-cased\", id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8665bf2-ea57-43ab-b836-995b257390fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\OneDrive\\Documents\\GitHub\\reddit_2023\\env\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ad7f276483483ebbc42653a03db637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb68adf6161046b3a2ca834c43df2707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004731182474642992, 'eval_precision': 0.6996336996336996, 'eval_recall': 0.9052132701421801, 'eval_f1': 0.7892561983471073, 'eval_accuracy': 0.9978626658005574, 'eval_runtime': 51.972, 'eval_samples_per_second': 4.849, 'eval_steps_per_second': 0.308, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9331c889e4a24ced9b7b2d29e494b974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004006328526884317, 'eval_precision': 0.718978102189781, 'eval_recall': 0.933649289099526, 'eval_f1': 0.8123711340206186, 'eval_accuracy': 0.9980931626259875, 'eval_runtime': 53.5635, 'eval_samples_per_second': 4.705, 'eval_steps_per_second': 0.299, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e9a09ca856449da49327eb651f1286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.003824098501354456, 'eval_precision': 0.7351778656126482, 'eval_recall': 0.8815165876777251, 'eval_f1': 0.8017241379310345, 'eval_accuracy': 0.9980722083691302, 'eval_runtime': 53.274, 'eval_samples_per_second': 4.73, 'eval_steps_per_second': 0.3, 'epoch': 3.0}\n",
      "{'loss': 0.0115, 'learning_rate': 3.23943661971831e-05, 'epoch': 3.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e27f6b35e0b4a8a9fff80ce5a1e40a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004087214358150959, 'eval_precision': 0.75, 'eval_recall': 0.7819905213270142, 'eval_f1': 0.7656612529002321, 'eval_accuracy': 0.9978836200574147, 'eval_runtime': 54.4552, 'eval_samples_per_second': 4.628, 'eval_steps_per_second': 0.294, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6961f58983aa4603b4f9f8964bdec814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004275472369045019, 'eval_precision': 0.7364016736401674, 'eval_recall': 0.8341232227488151, 'eval_f1': 0.7822222222222223, 'eval_accuracy': 0.9979464828279865, 'eval_runtime': 54.062, 'eval_samples_per_second': 4.661, 'eval_steps_per_second': 0.296, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c96fb81c96146cfa77e04fafe2dc9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004715894348919392, 'eval_precision': 0.7564102564102564, 'eval_recall': 0.8388625592417062, 'eval_f1': 0.7955056179775282, 'eval_accuracy': 0.9980931626259875, 'eval_runtime': 51.8556, 'eval_samples_per_second': 4.86, 'eval_steps_per_second': 0.309, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d560c61f244a3f85940e11ee50c450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004880106542259455, 'eval_precision': 0.7510729613733905, 'eval_recall': 0.8293838862559242, 'eval_f1': 0.7882882882882883, 'eval_accuracy': 0.9980302998554156, 'eval_runtime': 51.4664, 'eval_samples_per_second': 4.896, 'eval_steps_per_second': 0.311, 'epoch': 7.0}\n",
      "{'loss': 0.0027, 'learning_rate': 1.4788732394366198e-05, 'epoch': 7.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ba3eb095c5400a97032c8e2ccc7148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.004889966920018196, 'eval_precision': 0.7671232876712328, 'eval_recall': 0.7962085308056872, 'eval_f1': 0.7813953488372093, 'eval_accuracy': 0.9980302998554156, 'eval_runtime': 57.1764, 'eval_samples_per_second': 4.407, 'eval_steps_per_second': 0.28, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276d73837cef431ba31c3c14d6eb336c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.00504990853369236, 'eval_precision': 0.7489177489177489, 'eval_recall': 0.8199052132701422, 'eval_f1': 0.7828054298642535, 'eval_accuracy': 0.997988391341701, 'eval_runtime': 56.2811, 'eval_samples_per_second': 4.478, 'eval_steps_per_second': 0.284, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49709c87bb3c4fb095c84ff6af52f2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.005608788691461086, 'eval_precision': 0.7489177489177489, 'eval_recall': 0.8199052132701422, 'eval_f1': 0.7828054298642535, 'eval_accuracy': 0.997988391341701, 'eval_runtime': 53.8386, 'eval_samples_per_second': 4.681, 'eval_steps_per_second': 0.297, 'epoch': 10.0}\n",
      "{'train_runtime': 12431.9179, 'train_samples_per_second': 1.822, 'train_steps_per_second': 0.114, 'train_loss': 0.0056380587984138815, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1420, training_loss=0.0056380587984138815, metrics={'train_runtime': 12431.9179, 'train_samples_per_second': 1.822, 'train_steps_per_second': 0.114, 'train_loss': 0.0056380587984138815, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/age_token_classification\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ner_labels[\"train\"],\n",
    "    eval_dataset=tokenized_ner_labels[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4200002c-1936-4491-ab1b-16656718cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/age_token_classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6cbec-3f75-454c-9935-b92afd9accb6",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b6d9e-8e74-4ae9-bb05-f5bb3c63f132",
   "metadata": {},
   "source": [
    "## Single Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dadc49e6-565a-40c7-8a98-562c65406d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../reddit_api.json') as json_file:\n",
    "    reddit_api_credentials = json.load(json_file)\n",
    "    reddit_read_only = praw.Reddit(client_id=reddit_api_credentials['client_id'],\n",
    "                                   client_secret=reddit_api_credentials['secret'],\n",
    "                                   user_agent=reddit_api_credentials['user_agent']) \n",
    "\n",
    "subreddit = reddit_read_only.subreddit(\"AskDocs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1da96dda-97ca-40b6-82d5-a5928947c13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Week-long swollen foot w/painful lump.\\n37 y/o male. \\n\\nFirst noticed soreness on the top of my foot near my pinky toe last Tuesday (7/18). Slight swelling and redness of the area began the next day and has continued since. A small bump that I don’t *think* is a blister formed either Tuesday or Wednesday. The pain is concentrated around this spot/bump and extends to the bottom of my foot as well, making it hard to walk on without a limp. The spot itself feels hard and is quite sore when touched. Pain level fluctuates and all symptoms seem worse at night.\\n\\nNot sure if it’s a bite or something else. The swelling increases/decreases with activity level but hasn’t completely resided at all in a week unless I’ve taken Ibuprofen. \\n\\nIt still being pretty sore to walk on and still having slight swelling after an entire week makes me wonder if it’s time for an office visit or if this is one of those “Yeah, just keep taking Advil if it makes the swelling reside” situations?\\n\\nPhotos: https://imgur.com/a/3NO3rjD'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_post = subreddit.random()\n",
    "context = f\"{random_post.title}\\n{random_post.selftext}\"\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f1d8123-1f40-4daf-9ed1-23cea8f4fd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-age',\n",
       "  'score': 0.74721,\n",
       "  'index': 11,\n",
       "  'word': '37',\n",
       "  'start': 39,\n",
       "  'end': 41},\n",
       " {'entity': 'B-age_unit',\n",
       "  'score': 0.91090286,\n",
       "  'index': 12,\n",
       "  'word': 'y',\n",
       "  'start': 42,\n",
       "  'end': 43}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "age_extractor = pipeline(\"ner\", model=\"../models/age_token_classification\", tokenizer=tokenizer)\n",
    "age_extractor(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7369b21-2f10-49cd-971e-e30cb8e2417b",
   "metadata": {},
   "source": [
    "## Entire Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28cd41ac-a2df-4dbb-82cf-ef6ea4825923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55709d9db7954f37bb6d1e1b84735602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.003824098501354456,\n",
       " 'eval_precision': 0.7351778656126482,\n",
       " 'eval_recall': 0.8815165876777251,\n",
       " 'eval_f1': 0.8017241379310345,\n",
       " 'eval_accuracy': 0.9980722083691302,\n",
       " 'eval_runtime': 54.0072,\n",
       " 'eval_samples_per_second': 4.666,\n",
       " 'eval_steps_per_second': 0.296,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d169bef-7a5e-4b1f-bd51-d2067a6554cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
